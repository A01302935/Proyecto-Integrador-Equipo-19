## ITESM
## Maestria en Inteligencia Artificial Aplicada (MNA)
## Proyecto Integrador (Grupo 10)
## Avance 1. An치lisis exploratorio de datos Equipo 19
### Alumnos:
## [A01302935] David Mireles Samaniego
## [A00618978] Angel Rodr칤guez Cardenas       

##::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

## Primeramente instalar la biblioteca cv2 en la terminal con el comando: pip install opencv-python 
## Despues instalar la biblioteca imutils en la terminal con el comando: pip install imutils
## Despues instalar la biblioteca Pillow en la terminal con el comando: pip install Pillow
## Despues instalar la biblioteca Pandas en la terminal con el comando: pip install pandas
## Despues instalar la biblioteca atplotlib en la terminal con el comando:pip install matplotlib
## Despues instalar la biblioteca scipy en la terminal con el comando: pip install scipy
## pip install -U scikit-learn
## pip install seaborn

## Muy importante importar la libreria 'haarcascade_frontalface_default.xml'

import cv2
import os
import imutils

personName = 'David'
dataPath = 'C:/Users/polvo/VISUALSTUDIO_ITESM/VERSION FACIL/Data'
personPath = dataPath + '/' + personName

if not os.path.exists(personPath):
    print('Carpeta creada: ',personPath)
    os.makedirs(personPath)


cap = cv2.VideoCapture('David.mp4')
faceClassif = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')
count = 0

while True:    
    ret, frame = cap.read()
    if ret == False: break
    frame =  imutils.resize(frame, width=640)
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    auxFrame = frame.copy()

    faces = faceClassif.detectMultiScale(gray,1.3,5)

    for (x,y,w,h) in faces:
        cv2.rectangle(frame, (x,y),(x+w,y+h),(0,255,0),2)
        rostro = auxFrame[y:y+h,x:x+w]
        rostro = cv2.resize(rostro,(150,150),interpolation=cv2.INTER_CUBIC)
        cv2.imwrite(personPath + '/rotro_{}.jpg'.format(count),rostro)
        count = count + 1
    cv2.imshow('frame',frame)

    k =  cv2.waitKey(1)
    if k == 27 or count >= 300:
        break

cap.release()
cv2.destroyAllWindows()


#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
#Las siguientes son algunas de las preguntas comunes que podr치n abordar a trav칠s del EDA:

#_________________________________________________________________________________________________________________________________________________________
#쮿ay valores faltantes en el conjunto de datos? 쯉e pueden identificar patrones de ausencia? 

import os
from PIL import Image

def check_missing_or_invalid_images(folder_path):
    """
    Verifica im치genes faltantes, corruptas o inv치lidas en una carpeta.

    Args:
        folder_path (str): Ruta a la carpeta con im치genes.

    Returns:
        dict: Informaci칩n sobre im치genes faltantes o inv치lidas.
    """
    missing_files = []
    corrupt_files = []
    invalid_images = []

    # Listar archivos en la carpeta
    all_files = os.listdir(folder_path)
    image_files = [f for f in all_files if f.lower().endswith((".jpg", ".jpeg", ".png", ".bmp"))]

    for file_name in image_files:
        file_path = os.path.join(folder_path, file_name)
        try:
            with Image.open(file_path) as img:
                # Verificar dimensiones y p칤xeles
                width, height = img.size

                if width == 0 or height == 0:
                    invalid_images.append(file_name)

                # Opcional: verificar si la imagen tiene p칤xeles uniformes
                if img.getextrema() == ((0, 0),):  # Ejemplo para im치genes completamente negras
                    invalid_images.append(file_name)

        except Exception as e:
            corrupt_files.append((file_name, str(e)))

    return {
        "total_files": len(all_files),
        "total_images": len(image_files),
        "missing_files": missing_files,
        "corrupt_files": corrupt_files,
        "invalid_images": invalid_images,
    }

# Ejemplo de uso
if __name__ == "__main__":
    folder_path = "C:/Users/polvo/VISUALSTUDIO_ITESM/VERSION FACIL/Data/David"  # Cambia esto por la ruta a tu conjunto de im치genes
    report = check_missing_or_invalid_images(folder_path)

    print("\nReporte de valores faltantes o inv치lidos:")
    for key, value in report.items():
        print(f"{key}: {value}")

    if report["corrupt_files"]:
        print("\nIm치genes corruptas:")
        for file, error in report["corrupt_files"]:
            print(f"{file}: {error}")

    if report["invalid_images"]:
        print("\nIm치genes inv치lidas:")
        for file in report["invalid_images"]:
            print(file)

#En el an치lisis de im치genes por computadora, los valores faltantes pueden aparecer de diversas formas y afectan la calidad del an치lisis.
#Algunos ejemplos errores y sus formas de identificar patrones de ausencia, son:

#CAUSAS COMUNES DE LOS VALORES FALTANTES EN IMAGENES

#1.- Pixeles ausentes o da침ados:
#Algunas im치genes pueden tener regiones oscuras (valores constantes como 0 o NaN) debido a defectos en los sensores o compresi칩n excesiva.

#2.- Recortes o modificaciones:
#Partes de la imagen pueden estar recortadas o intencionalmente omitidas por preprocesamiento.

#3.- Canales incompletos:
#Falta de informaci칩n en ciertos canales de color (por ejemplo, RGB incompleto).

#4.- Errores en el etiquetado:
#En conjuntos de datos etiquetados, las etiquetas pueden estar ausentes o ser incorrectas.

#5.- Bloqueos u Colusiones:
#Partes del objeto de inter칠s pueden estar ocultas en las im치genes, dificultando la segmentaci칩n o clasificaci칩n.

# EN LOS DATOS CON LOS QUE SE HA ESTADO TRABAJANDO NO SE HA ENCONTRADO NINGUNO DE ESTOS TIPOS DE ERRORES

#_________________________________________________________________________________________________________________________________________________________
#쮺u치les son las estad칤sticas resumidas del conjunto de datos?

## Primeramente instalar la biblioteca pillow
## pip install Pillow
import os
from PIL import Image, ImageStat
import numpy as np

def get_image_statistics(image_path):
    """
    Calcula estad칤sticas b치sicas para una imagen dada.

    Args:
        image_path (str): Ruta de la imagen.

    Returns:
        dict: Estad칤sticas incluyendo tama침o, brillo promedio y contraste.
    """
    try:
        with Image.open(image_path) as img:
            # Convertir la imagen a escala de grises para analizar brillo y contraste
            grayscale_img = img.convert("L")
            
            # Obtener tama침o (resoluci칩n)
            width, height = img.size

            # Estad칤sticas b치sicas
            stat = ImageStat.Stat(grayscale_img)
            brightness = stat.mean[0]  # Promedio de brillo
            contrast = stat.stddev[0]  # Desviaci칩n est치ndar como medida de contraste

            return {
                "file_name": os.path.basename(image_path),
                "width": width,
                "height": height,
                "brightness": brightness,
                "contrast": contrast,
            }
    except Exception as e:
        print(f"Error procesando {image_path}: {e}")
        return None

def analyze_image_dataset(folder_path):
    """
    Analiza un conjunto de im치genes en una carpeta para calcular estad칤sticas resumidas.

    Args:
        folder_path (str): Ruta a la carpeta con im치genes.

    Returns:
        dict: Estad칤sticas generales del conjunto de im치genes.
    """
    all_stats = []

    # Iterar sobre las im치genes en la carpeta
    for file_name in os.listdir(folder_path):
        file_path = os.path.join(folder_path, file_name)
        if os.path.isfile(file_path) and file_name.lower().endswith((".jpg", ".jpeg", ".png", ".bmp")):
            stats = get_image_statistics(file_path)
            if stats:
                all_stats.append(stats)

    # Calcular estad칤sticas resumidas
    if all_stats:
        widths = [s["width"] for s in all_stats]
        heights = [s["height"] for s in all_stats]
        brightnesses = [s["brightness"] for s in all_stats]
        contrasts = [s["contrast"] for s in all_stats]

        summary = {
            "total_images": len(all_stats),
            "average_width": np.mean(widths),
            "average_height": np.mean(heights),
            "average_brightness": np.mean(brightnesses),
            "average_contrast": np.mean(contrasts),
            "min_brightness": np.min(brightnesses),
            "max_brightness": np.max(brightnesses),
            "min_contrast": np.min(contrasts),
            "max_contrast": np.max(contrasts),
        }

        return summary, all_stats
    else:
        print("No se encontraron im치genes v치lidas en la carpeta.")
        return None, None

# Ejemplo de uso
if __name__ == "__main__":
    folder_path = "C:/Users/polvo/VISUALSTUDIO_ITESM/VERSION FACIL/Data/David"  # Cambia esto por la ruta a tu conjunto de im치genes
    summary, all_stats = analyze_image_dataset(folder_path)

    if summary:
        print("\nEstad칤sticas resumidas del conjunto de im치genes:")
        for key, value in summary.items():
            print(f"{key}: {value}")

        print("\nDetalles por imagen:")
        for stats in all_stats:
            print(stats)

#Estad칤sticas comunes de im치genes
#Dimensiones: 
# Del video 1280 X 720  pixeles y de las imagenes 150 X 150 pixeles

#Promedio, m칤nimo, m치ximo y rango de alturas y anchuras de las im치genes en p칤xeles.
#imagenes 150 X 150 pixeles en todos los datos

#Proporci칩n de aspectos (ancho/alto). Ancho 99 ppp y Alto 99 ppp
#Distribuci칩n de intensidad: Proporcion 1:1 a 150 X 150 pixeles, profundidad de bits 24

#Promedio y desviaci칩n est치ndar de los valores de los p칤xeles por canal (RGB, escala de grises, etc.).
#Histogramas de intensidad para cada canal.
#Tama침o de archivo: Alrrededor de 8.2KB por imagen, en formato .jpg

#Promedio, m칤nimo y m치ximo de los tama침os de los archivos en kilobytes o megabytes.
#N칰mero de canales:Alrrededor de 8KB por imagen

#Distribuci칩n de im치genes con diferentes configuraciones de canales (por ejemplo, RGB, RGBA, escala de grises).
#Rango din치mico: RGB

#Rango de valores de p칤xeles por canal (e.g., 0-255 para im치genes de 8 bits).  Ancho 99 ppp y Alto 99 ppp


#_________________________________________________________________________________________________________________________________________________________
#쮿ay valores at칤picos en el conjunto de datos?


import numpy as np
import cv2
import os

# Funci칩n para cargar las im치genes de un directorio
def cargar_imagenes(directorio):
    imagenes = []
    for archivo in os.listdir('C:/Users/polvo/VISUALSTUDIO_ITESM/VERSION FACIL/Data/David'):
        if archivo.endswith('.jpg') or archivo.endswith('.png'):
            img = cv2.imread(os.path.join(directorio, archivo), cv2.IMREAD_GRAYSCALE)
            if img is not None:
                imagenes.append(img)
    return imagenes

# Funci칩n para detectar valores at칤picos en las im치genes
def detectar_valores_atipicos(imagenes, umbral=3):
    valores_pixel = []
    
    # Extraer los valores de los p칤xeles de todas las im치genes
    for img in imagenes:
        valores_pixel.extend(img.flatten())
    
    valores_pixel = np.array(valores_pixel)
    
    # Calcular la media y la desviaci칩n est치ndar
    media = np.mean(valores_pixel)
    desviacion_estandar = np.std(valores_pixel)
    
    # Detectar los valores at칤picos basados en el umbral de desviaci칩n est치ndar
    atipicos = valores_pixel[np.abs(valores_pixel - media) > umbral * desviacion_estandar]
    
    return atipicos

# Directorio donde se encuentran las im치genes
directorio_imagenes = 'ruta/a/las/imagenes'

# Cargar las im치genes
imagenes = cargar_imagenes(directorio_imagenes)

# Detectar valores at칤picos
valores_atipicos = detectar_valores_atipicos(imagenes)

# Imprimir el n칰mero de valores at칤picos
print(f"Se encontraron {len(valores_atipicos)} valores at칤picos.")



#_________________________________________________________________________________________________________________________________________________________
#쮺u치l es la cardinalidad de las variables categ칩ricas?

# Aun no tenemos los datos en un modelo de redes neuronales para poder etiquetarlo pero algo basico que podemos hacer es:
import pandas as pd

# Simulaci칩n de un conjunto de datos con etiquetas de im치genes
# Imagina que tenemos un DataFrame con los nombres de las im치genes y sus etiquetas
data = {
    'imagen': ['rotro_0.jpg', 'rotro_1.jpg', 'rotro_2.jpg', 'rotro_3.jpg', 'rotro_4.jpg'],
    'etiqueta': ['feliz', 'sorprendido', 'angustiado', 'ansioso', 'confusion']
}

df = pd.DataFrame(data)

# Calcular la cardinalidad de la variable categ칩rica 'etiqueta'
cardinalidad_etiquetas = df['etiqueta'].nunique()

# Imprimir la cardinalidad
print(f"La cardinalidad de las etiquetas es: {cardinalidad_etiquetas}")

#La cardinalidad de las variables categ칩ricas en el an치lisis de rostros en visi칩n por computadora depende de las tareas espec칤ficas y los tipos de etiquetas 
#utilizadas. A continuaci칩n, se describen las variables categ칩ricas comunes y su cardinalidad esperada:
# aun no tenemos un modelo de redes nuronales que nos pueda dar esos valores

#VARIABLES CATEG칍RICAS Y CARDINILIDAD T칈PICA.
#1.- Identidad de las personas (ID):

#   1.-Descripci칩n: Representa a individuos 칰nicos en el conjunto de datos.
#   *Cardinalidad: Alta, dependiendo del n칰mero de personas en el conjunto (puede variar de decenas a miles).
#       *Ejemplo:
#           *LFW (Labelled Faces in the Wild): ~5,700 identidades.
#           *VGGFace2: ~9,000 identidades.
#   2.-G칠nero:
#   *Descripci칩n: Masculino, femenino, u otras categor칤as de g칠nero.
#   *Cardinalidad: Generalmente baja (2-3 categor칤as).
#       *Ejemplo: Masculino, Femenino, No especificado.
#   3.-Edad:
#   *Descripci칩n: Rangos de edad o categor칤as espec칤ficas (ni침o, adolescente, adulto, anciano).
#   *Cardinalidad: Puede ser baja o moderada, dependiendo de c칩mo se agrupe la edad.
#       *Ejemplo:
#           *Rangos: [0-10], [11-20], ..., [60+].
#           *Clases exactas (edad espec칤fica): 0-100.
#   4.-Expresiones faciales:
#   *Descripci칩n: Categor칤as de emociones detectadas en el rostro.
#   *Cardinalidad: Generalmente baja, con 6-8 clases est치ndar.
#       Ejemplo: Felicidad, Tristeza, Sorpresa, Enojo, Miedo, Desagrado, Neutral.
#   5.- Accesorios:
#   *Descripci칩n: Presencia de objetos como gafas, sombreros, m치scaras, etc.
#   *Cardinalidad: Baja, dependiendo del tipo de accesorio.
#       *Ejemplo: Gafas (s칤/no), Sombrero (s칤/no).
#           *Orientaci칩n de la cabeza (Pose):
#   6.- Descripci칩n: Direcci칩n en la que est치 orientado el rostro.
#   *Cardinalidad: Baja, con clases como Frontal, Izquierda, Derecha, Arriba, Abajo.
#       *Ejemplo: 5-10 categor칤as para 치ngulos discretizados.
#           *Iluminaci칩n:
#   7.-Descripci칩n: Categor칤as basadas en las condiciones de iluminaci칩n (natural, artificial, etc.).
#   *Cardinalidad: Baja, con clases predefinidas.
#       *Ejemplo: Iluminaci칩n tenue, media, brillante.
#           *Casos con cardinalidad elevada
#           *En algunos casos, la cardinalidad puede ser muy alta:
#   8.-Identidades con miles de personas.
#   *Accesorios combinados: Presencia de m칰ltiples combinaciones de accesorios (por ejemplo, gafas + sombrero).
#   *Para manejar estos casos, es com칰n usar t칠cnicas de reducci칩n de dimensionalidad o agrupar categor칤as menos 
#   *frecuentes en una sola clase ("Otros").


#_________________________________________________________________________________________________________________________________________________________
#쮼xisten distribuciones sesgadas en el conjunto de datos? 쯅ecesitamos aplicar alguna transformaci칩n no lineal?

import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import boxcox
import cv2
import os

# Funci칩n para cargar las im치genes de un directorio y convertirlas en escala de grises
def cargar_imagenes(directorio):
    imagenes = []
    for archivo in os.listdir(directorio):
        if archivo.endswith('.jpg') or archivo.endswith('.png'):
            img = cv2.imread(os.path.join(directorio, archivo), cv2.IMREAD_GRAYSCALE)
            if img is not None:
                imagenes.append(img)
    return imagenes

# Funci칩n para extraer caracter칤sticas de las im치genes (por ejemplo, media de los p칤xeles)
def extraer_caracteristicas(imagenes):
    caracter칤sticas = []
    for img in imagenes:
        caracter칤sticas.append(np.mean(img))  # Caracter칤stica simple: media de los p칤xeles
    return np.array(caracter칤sticas)

# Visualizaci칩n de la distribuci칩n y transformaci칩n
def visualizar_transformacion(caracter칤sticas):
    # Distribuci칩n original
    plt.subplot(1, 2, 1)
    plt.hist(caracter칤sticas, bins=20)
    plt.title('Distribuci칩n Original')

    # Transformaci칩n logar칤tmica
    caracter칤sticas_log = np.log1p(caracter칤sticas)  # Usamos log1p para manejar ceros
    plt.subplot(1, 2, 2)
    plt.hist(caracter칤sticas_log, bins=20)
    plt.title('Distribuci칩n despu칠s de Transformaci칩n Logar칤tmica')

    plt.show()

# Directorio donde se encuentran las im치genes
directorio_imagenes = 'C:/Users/polvo/VISUALSTUDIO_ITESM/VERSION FACIL/Data/David'

# Cargar las im치genes
imagenes = cargar_imagenes(directorio_imagenes)

# Extraer caracter칤sticas (en este caso, la media de los p칤xeles)
caracter칤sticas = extraer_caracteristicas(imagenes)

# Visualizar distribuci칩n original y transformada
visualizar_transformacion(caracter칤sticas)

# Aplicar transformaci칩n de Box-Cox si la distribuci칩n tiene valores positivos
if np.all(caracter칤sticas > 0):
    caracter칤sticas_boxcox, _ = boxcox(caracter칤sticas)
    plt.hist(caracter칤sticas_boxcox, bins=20)
    plt.title('Distribuci칩n despu칠s de Box-Cox')
    plt.show()
else:
    print("No se puede aplicar Box-Cox a caracter칤sticas con valores negativos o cero.")

#En el an치lisis de rostros con visi칩n por computadora, es com칰n encontrar distribuciones sesgadas en el conjunto de datos, lo que puede afectar la eficacia del modelo y 
#requerir transformaciones no lineales para mejorar la representaci칩n o el aprendizaje. Aqu칤 te detallo los aspectos clave:

#Distribuciones sesgadas t칤picas en an치lisis de rostros
#Distribuci칩n de clases (sesgo de clase):

#En tareas como clasificaci칩n de identidades o expresiones faciales, algunas clases suelen estar sobrerrepresentadas (por ejemplo, rostros de adultos j칩venes)
#mientras que otras tienen menos ejemplos (ni침os o ancianos).
#Impacto: Los modelos pueden inclinarse hacia las clases mayoritarias, ignorando las minoritarias.
#Distribuci칩n de edades:

#Frecuentemente sesgada hacia adultos j칩venes, con menos ejemplos de ni침os y personas mayores.
#Impacto: Modelos de estimaci칩n de edad pueden ser inexactos para grupos menos representados.
#Distribuci칩n de poses:

#Sesgo hacia poses frontales, ya que muchas im치genes de entrenamiento est치n tomadas en condiciones controladas.
#Impacto: El modelo podr칤a tener dificultades para generalizar a poses laterales o inusuales.
#Distribuci칩n de iluminaci칩n:

#Sesgo hacia iluminaci칩n uniforme o brillante en im치genes capturadas en estudios, mientras que las condiciones reales pueden incluir sombras o poca luz.
#Impacto: Modelos podr칤an fallar en ambientes con iluminaci칩n desigual.
#Distribuci칩n de g칠nero y etnicidad:

#Conjuntos de datos de rostros tienden a estar dominados por ciertos g칠neros o grupos 칠tnicos (por ejemplo, hombres cauc치sicos).
#Impacto: Reducci칩n en la equidad y precisi칩n para otros grupos.
#Cu치ndo aplicar transformaciones no lineales
#Transformaciones no lineales pueden ser 칰tiles en diferentes contextos del an치lisis de rostros:

#Para reducir el sesgo en los datos de entrada:

#Normalizaci칩n no lineal: Transformaciones como ra칤z cuadrada o logaritmo pueden ayudar a manejar distribuciones de intensidad o brillo muy sesgadas.
#Ejemplo: Aplicar: 
#log(1+洧논)
#log(1+x) para valores de intensidad de p칤xeles en im치genes de alto rango din치mico.
#Para mejorar la separaci칩n de caracter칤sticas:

#Mapeos no lineales en representaciones latentes: Usar arquitecturas profundas que transformen las im치genes originales en espacios latentes m치s 칰tiles.
#Ejemplo: Redes neuronales convolucionales (CNNs) ya aplican transformaciones no lineales mediante funciones como ReLU o Swish.
#Para ajustar la distribuci칩n de clases:

#Sobremuestreo/Sobreescritura: Aplicar t칠cnicas como SMOTE o reponderar clases minoritarias en las p칠rdidas.
#Para manejar variaciones de escala:

#Transformaciones gamma: A menudo utilizadas en la preprocesamiento de im치genes para normalizar la iluminaci칩n desigual.
#Ejemplo de aplicaci칩n pr치ctica
#T칠cnicas de balance de clases:

#Aplicar ponderaci칩n en la funci칩n de p칠rdida para que las clases minoritarias tengan mayor importancia.
#Recolecci칩n de m치s datos o generaci칩n de datos sint칠ticos para equilibrar clases.
#Normalizaci칩n en distribuciones altamente sesgadas:

#Escalado no lineal en caracter칤sticas como brillo, contraste o rango de edades.
#Augmentaci칩n de datos:

#Introducir variaciones de pose, iluminaci칩n y expresiones para reducir el sesgo en las distribuciones.



#_________________________________________________________________________________________________________________________________________________________
#쯉e identifican tendencias temporales? (En caso de que el conjunto incluya una dimensi칩n de tiempo).


# No aplica para la naturaleza del proyecto y los datos con los que se trabajara


#_________________________________________________________________________________________________________________________________________________________
#쮿ay correlaci칩n entre las variables dependientes e independientes?

#En nuestra base de datos falta aun que agregemos etiquetas, pero el script que proponemos seria de este tipo, pues aun no tenemos nuestro modelo entrenado
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import pearsonr

# Sup칩n que tienes un DataFrame con caracter칤sticas extra칤das (por ejemplo, PCA o caracter칤sticas de la cara) y etiquetas
# Ejemplo con caracter칤sticas num칠ricas y etiquetas de clase

# Simulaci칩n de caracter칤sticas (independientes) y etiquetas de clase (dependientes)
np.random.seed(42)
num_imagenes = 100

# Caracter칤sticas num칠ricas (por ejemplo, valores extra칤dos de las im치genes)
caracteristicas = np.random.rand(num_imagenes, 5)  # 5 caracter칤sticas extra칤das de las im치genes

# Etiquetas de clase (por ejemplo, identidades de las personas)
etiquetas = np.random.choice(['persona_1', 'persona_2', 'persona_3'], size=num_imagenes)

# Crear un DataFrame
df = pd.DataFrame(caracteristicas, columns=[f'caracteristica_{i+1}' for i in range(5)])
df['etiqueta'] = etiquetas

# 1. Correlaci칩n de Pearson entre caracter칤sticas num칠ricas (variables independientes)
corr_matrix = df.drop('etiqueta', axis=1).corr()  # Eliminar la columna de etiquetas
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')
plt.title("Matriz de Correlaci칩n de Pearson entre Caracter칤sticas")
plt.show()

# 2. Correlaci칩n de Cram칠r's V entre las caracter칤sticas y las etiquetas (variables categ칩ricas)
# Para correlaci칩n entre variables categ칩ricas, usaremos una funci칩n personalizada para Cram칠r's V

import scipy.stats as stats

def cramers_v(categoria1, categoria2):
    contingency_table = pd.crosstab(categoria1, categoria2)
    chi2, p, dof, expected = stats.chi2_contingency(contingency_table)
    n = contingency_table.sum().sum()
    phi2 = chi2 / n
    r, k = contingency_table.shape
    return np.sqrt(phi2 / min(k - 1, r - 1))

# Calcular la correlaci칩n de Cram칠r's V entre la variable de etiqueta y las caracter칤sticas
for column in df.drop('etiqueta', axis=1).columns:
    correlation_cramers_v = cramers_v(df[column], df['etiqueta'])
    print(f"Correlaci칩n de Cram칠r's V entre {column} y 'etiqueta': {correlation_cramers_v:.4f}")

#En el an치lisis de rostros con visi칩n por computadora, es com칰n investigar la correlaci칩n entre las variables dependientes (etiquetas o predicciones, como:
#edad, g칠nero, expresi칩n facial, etc.) y las variables independientes (caracter칤sticas extra칤das de las im치genes). A continuaci칩n, exploramos este aspecto 
#con detalle:

#Correlaci칩n entre variables en an치lisis de rostros
#1.- Variables dependientes comunes:

#       Edad.
#       G칠nero.
#       Expresi칩n facial.
#       Identidad de personas.
#       Pose (orientaci칩n de la cabeza).
#       Variables independientes comunes:

#2.- Caracter칤sticas de los p칤xeles (valores RGB, texturas).
#       Caracter칤sticas de alto nivel extra칤das por modelos (embeddings o representaciones latentes).
#       Factores externos (iluminaci칩n, fondo, accesorios).

#       Ejemplos de correlaci칩n esperada
#       1.- Edad y textura facial:

#           Correlaci칩n:
#           Las arrugas y cambios en la textura de la piel son fuertes predictores de la edad.
#       An치lisis:
#           La textura de bajo nivel (frecuencias espaciales altas) tiene correlaci칩n positiva con el envejecimiento.
#           Representaciones profundas (como embeddings de redes neuronales) tambi칠n capturan esta correlaci칩n.
#       2.-G칠nero y forma facial:

#       Correlaci칩n:
#           Caracter칤sticas como la forma del rostro, la mand칤bula o la distribuci칩n del cabello tienden a correlacionarse con el g칠nero en ciertos conjuntos de datos.
#           Limitaci칩n:
#           Estas correlaciones pueden estar sesgadas si el conjunto de datos no es diverso (e.g., sesgo 칠tnico o cultural).
#       3.-Expresi칩n facial y regiones espec칤ficas:

#           Correlaci칩n:
#           Los movimientos de los m칰sculos faciales (sonrisa, ce침o fruncido, etc.) afectan ciertas 치reas del rostro, como los ojos y la boca.
#           An치lisis:
#                Redes convolucionales suelen asignar mayor importancia a estas regiones al clasificar expresiones.
#       4.-Pose y caracter칤sticas de fondo:

#           Correlaci칩n:
#           Las poses extremas pueden influir en la percepci칩n de la identidad y las caracter칤sticas faciales.
#       5.-Accesorios y variables dependientes:

#           Correlaci칩n negativa:
#           Gafas o m치scaras pueden reducir la precisi칩n en la predicci칩n de g칠nero, expresi칩n o edad.

# M칠todos para medir correlaciones
#An치lisis estad칤stico:

#Coeficientes de correlaci칩n:
#Usar m칠tricas como Pearson, Spearman o Kendall para medir la correlaci칩n entre variables continuas (e.g., edad y caracter칤sticas latentes).
#Matrices de correlaci칩n:
#Evaluar la relaci칩n entre m칰ltiples variables.
#An치lisis basado en modelos:

#Importancia de caracter칤sticas:
#Usar modelos interpretables (e.g., 치rboles de decisi칩n) para identificar qu칠 variables independientes influyen m치s en las predicciones.
#Mapas de calor activados por gradiente (Grad-CAM):
#Visualizar regiones de la imagen relevantes para la predicci칩n.
#An치lisis en el espacio latente:

#Evaluar c칩mo se agrupan o separan las clases (g칠nero, expresi칩n, etc.) en un espacio de embeddings mediante t칠cnicas como t-SNE o PCA.

#Desaf칤os de la correlaci칩n
#Sesgo en los datos:

#Correlaciones aparentes pueden ser artefactos del conjunto de datos, no propiedades reales (e.g., g칠nero correlacionado con fondo o iluminaci칩n).
#Correlaciones espurias:

#Factores no relacionados (como el fondo de la imagen) pueden influir en la predicci칩n.
#Multicolinealidad:

#Algunas variables independientes pueden estar altamente correlacionadas entre s칤, afectando la interpretaci칩n del modelo.

#_________________________________________________________________________________________________________________________________________________________
#쮺칩mo se distribuyen los datos en funci칩n de diferentes categor칤as? (an치lisis bivariado)
# Aun no tenemos los datos entrenados pero el scrip propuesto seria de esta forma
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA

# Simulaci칩n de un conjunto de datos
np.random.seed(42)
num_imagenes = 100

# Simulamos caracter칤sticas extra칤das de las im치genes (por ejemplo, PCA)
caracteristicas = np.random.rand(num_imagenes, 5)  # 5 caracter칤sticas extra칤das

# Simulamos etiquetas de clase (identidades de las personas)
etiquetas = np.random.choice(['persona_1', 'persona_2', 'persona_3'], size=num_imagenes)

# Crear un DataFrame
df = pd.DataFrame(caracteristicas, columns=[f'caracteristica_{i+1}' for i in range(5)])
df['etiqueta'] = etiquetas

# 1. An치lisis bivariado usando un Diagrama de Cajas (Boxplot) para observar la distribuci칩n de caracter칤sticas por etiqueta
plt.figure(figsize=(12, 6))
sns.boxplot(x='etiqueta', y='caracteristica_1', data=df)  # Comparar 'caracteristica_1' entre diferentes personas
plt.title('Distribuci칩n de Caracter칤stica 1 por Etiqueta')
plt.show()

# 2. An치lisis bivariado usando un Histograma Apilado (Stacked Histogram)
plt.figure(figsize=(12, 6))
sns.histplot(data=df, x='caracteristica_1', hue='etiqueta', multiple='stack', kde=True)
plt.title('Distribuci칩n Apilada de Caracter칤stica 1 por Etiqueta')
plt.show()

# 3. An치lisis bivariado usando un Pairplot para explorar la relaci칩n entre m칰ltiples caracter칤sticas y las etiquetas
sns.pairplot(df, hue='etiqueta', vars=['caracteristica_1', 'caracteristica_2', 'caracteristica_3'])
plt.suptitle('Pairplot de Caracter칤sticas por Etiqueta', y=1.02)
plt.show()

#El an치lisis bivariado en visi칩n por computadora implica examinar c칩mo se distribuyen los datos entre diferentes categor칤as y c칩mo interact칰an dos variables 
#espec칤ficas, como una variable dependiente (etiquetas) y una independiente (caracter칤sticas o condiciones externas). Este an치lisis ayuda a identificar patrones, 
#sesgos o relaciones significativas. Aqu칤 te detallo c칩mo abordar el an치lisis bivariado en este contexto:

#1. An치lisis por pares de variables comunes
#a) Identidad y Expresi칩n Facial
#Ejemplo: Distribuci칩n de expresiones (felicidad, tristeza, enojo) en funci칩n de las identidades.
#Gr치ficos sugeridos:
#Diagramas de barras apiladas: Muestran la proporci칩n de cada expresi칩n por identidad.
#Heatmaps: Muestran frecuencias para combinaciones de identidad y expresi칩n.
#b) Edad y G칠nero
#Ejemplo: Distribuci칩n de edades separadas por g칠nero.
#Gr치ficos sugeridos:
#Histogramas por grupos: Comparar la distribuci칩n de edades para cada g칠nero.
#Boxplots: Evaluar diferencias en la dispersi칩n de edades entre g칠neros.
#c) Pose y Expresi칩n Facial
#Ejemplo: 쮿ay poses espec칤ficas asociadas con ciertas expresiones (e.g., cabeza inclinada al sonre칤r)?
#Gr치ficos sugeridos:
#Gr치ficos de dispersi칩n (pose en el eje x, expresi칩n como color o s칤mbolo).
#Diagramas de viol칤n: Muestran la densidad de poses asociadas con expresiones.
#d) Accesorios y Edad/G칠nero
#Ejemplo: Distribuci칩n de accesorios (como gafas) en funci칩n de g칠nero o edad.
#Gr치ficos sugeridos:
#Diagramas de barras agrupadas: Comparar la frecuencia de uso de gafas entre diferentes grupos.
#2. M칠todos para analizar la relaci칩n entre variables
#Tablas de contingencia:

#Evaluar frecuencias absolutas y relativas entre categor칤as de dos variables.
#Ejemplo: N칰mero de rostros masculinos y femeninos con cada expresi칩n facial.
#Coeficientes de correlaci칩n:

#Pearson, Spearman, o Chi-cuadrado para medir relaciones entre variables continuas (edad, pose) y categ칩ricas (g칠nero, expresi칩n).
#Test de independencia:

#Usar pruebas estad칤sticas como el test Chi-cuadrado para evaluar si las categor칤as son independientes.
#Ejemplo: 쯃a distribuci칩n de g칠nero es independiente de las expresiones?
#3. Identificaci칩n de sesgos y patrones
#El an치lisis bivariado puede revelar sesgos importantes en los datos:

#G칠nero y clase mayoritaria:
#Algunas expresiones (como enojo) pueden estar sobrerrepresentadas en un g칠nero.
#Edad y accesorios:
#Las gafas pueden ser m치s frecuentes en rangos de edad m치s altos.
#Etnicidad y expresi칩n:
#Sesgos hacia ciertas combinaciones (e.g., rostros cauc치sicos felices).
#4. Gr치ficos sugeridos
#Heatmaps:
#Visualizar frecuencias absolutas o relativas en una cuadr칤cula de dos variables categ칩ricas.
#Scatterplots con variables continuas:
#Ejemplo: Dispersi칩n entre pose y edad.
#Boxplots y diagramas de viol칤n:
#Evaluar distribuci칩n y dispersi칩n de una variable continua entre diferentes categor칤as.
#Gr치ficos apilados o de barras:
#Comparar proporciones entre categor칤as.
#Ejemplo pr치ctico
#Supongamos que tienes un conjunto de datos con:

#G칠nero (Masculino/Femenino).
#Expresi칩n facial (Happiness, Sadness, Anger).
#Edad (num칠rica).
#Paso 1: Tablas de contingencia
#Crear una tabla para mostrar la frecuencia de cada combinaci칩n de g칠nero y expresi칩n.

#G칠nero	Happiness	Sadness	Anger
#Masculino	500	200	150
#Femenino	600	250	100
#Paso 2: Gr치ficos de dispersi칩n
#Visualizar la relaci칩n entre la edad y la intensidad de felicidad en un gr치fico de dispersi칩n.

#Paso 3: Estad칤sticas de asociaci칩n
#Calcular correlaciones entre variables, como la intensidad de felicidad y la pose.


#_________________________________________________________________________________________________________________________________________________________
#쯉e deber칤an normalizar las im치genes para visualizarlas mejor?
# Para este proyecto no puesto que se pretende usar la misma camara en las mismas condiciones de luz para generar toda la base de datos necesaria
# Ademas con el scrip propuesto al inicio es suficiente con el recorte de 150 x 150 pixeles

#_________________________________________________________________________________________________________________________________________________________
#쮿ay desequilibrio en las clases de la variable objetivo?
# 
#El desequilibrio en las clases de la variable objetivo es un problema com칰n en el an치lisis de rostros con visi칩n por computadora. Esto ocurre cuando las 
#clases no est치n distribuidas uniformemente, lo que puede sesgar los modelos hacia las clases mayoritarias y reducir el rendimiento en las minoritarias.
#
# Los datos con los que se trabaja son bastante homogeneos y no necesitamos hacer ajustes